{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crude-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dataset': 'cifar10', 'decay': 0.0005, 'epochs': 10, 'learning_rate': 0.001, 'load': '', 'model': 'resnet18', 'momentum': 0.9, 'ngpu': 0, 'oe_batch_size': 256, 'prefetch': 4, 'save': './snapshots/oe_scratch', 'test_bs': 200}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Tunes a CIFAR Classifier with OE',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--dataset', type=str, choices=['cifar10', 'cifar100'], default='cifar10',\n",
    "                    help='Choose between CIFAR-10, CIFAR-100.')\n",
    "parser.add_argument('--model', '-m', type=str, default='resnet18',\n",
    "                    choices=['resnet18', 'resnet50'], help='Choose architecture.')\n",
    "# parser.add_argument('--calibration', '-c', action='store_true',\n",
    "#                     help='Train a model to be used for calibration. This holds out some data for validation.')\n",
    "# Optimization options\n",
    "parser.add_argument('--epochs', '-e', type=int, default=10, help='Number of epochs to train.')\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=0.001, help='The initial learning rate.')\n",
    "parser.add_argument('--batch_size', '-b', type=int, default=128, help='Batch size.')\n",
    "parser.add_argument('--oe_batch_size', type=int, default=256, help='Batch size.')\n",
    "parser.add_argument('--test_bs', type=int, default=200)\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='Momentum.')\n",
    "parser.add_argument('--decay', '-d', type=float, default=0.0005, help='Weight decay (L2 penalty).')\n",
    "# Checkpoints\n",
    "parser.add_argument('--save', '-s', type=str, default='./snapshots/oe_scratch', help='Folder to save checkpoints.')\n",
    "parser.add_argument('--load', '-l', type=str, default='', help='Checkpoint path to resume / test.')\n",
    "# parser.add_argument('--test', '-t', action='store_true', help='Test only flag.')\n",
    "# Acceleration\n",
    "parser.add_argument('--ngpu', type=int, default=0, help='0 = CPU.')\n",
    "parser.add_argument('--prefetch', type=int, default=4, help='Pre-fetching threads.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "state = {k: v for k, v in args._get_kwargs()}\n",
    "print(state)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "involved-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetOld(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetOld, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def forward_penul(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_penul(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
    "\n",
    "def ResNet34(num_classes=10):\n",
    "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet50(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet101(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
    "\n",
    "def ResNet152(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,8,36,3], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "streaming-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = trn.Compose([trn.RandomHorizontalFlip(), trn.RandomCrop(32, padding=4),\n",
    "                               trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    train_data_in = dset.CIFAR10('./data', train=True, transform=train_transform)\n",
    "    train_data_raw = dset.CIFAR10('./data', train=True)\n",
    "    test_data = dset.CIFAR10('./data', train=False, transform=test_transform)\n",
    "    num_classes = 10\n",
    "else:\n",
    "    train_data_in = dset.CIFAR100('./data', train=True, transform=train_transform)\n",
    "    test_data = dset.CIFAR100('./data', train=False, transform=test_transform)\n",
    "    num_classes = 100\n",
    "\n",
    "calib_indicator = ''\n",
    "# if args.calibration:\n",
    "#     train_data_in, val_data = validation_split(train_data_in, val_share=0.1)\n",
    "#     calib_indicator = '_calib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fedd826f760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data_raw[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "surgical-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def mixup_image(img1, img2, label1, label2, lam):\n",
    "    mixed_img = lam*np.asarray(img1) + (1-lam)*np.asarray(img2)\n",
    "    mixed_label = lam*label1 + (1-lam)*label2\n",
    "    return Image.fromarray(mixed_img.clip(0, 255).astype('uint8'), 'RGB'), mixed_label\n",
    "\n",
    "class MixupInputDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, lam_mag=0.5, lam_random=False, lam_direction='random'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.lam_mag = lam_mag\n",
    "        self.lam_random = lam_random\n",
    "        self.lam_direction = lam_direction\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img, label = self.dataset[idx]\n",
    "        idx2 = np.random.randint(0, len(self.dataset))\n",
    "        img2, label2 = self.dataset[idx2]\n",
    "        \n",
    "        if self.lam_random:\n",
    "            lam_mag = self.lam_mag * (0.5 + np.random.rand()/2)\n",
    "        else:\n",
    "            lam_mag = self.lam_mag\n",
    "        \n",
    "        print(lam_mag)\n",
    "        \n",
    "        if self.lam_direction == 'neg':\n",
    "            mixed_img, mixed_label = mixup_image(img, img2, label, label2, -lam_mag)\n",
    "        elif self.lam_direction == 'pos':\n",
    "            mixed_img, mixed_label = mixup_image(img, img2, label, label2, 1+lam_mag)\n",
    "        else:\n",
    "            if np.random.rand() > 0.5:\n",
    "                mixed_img, mixed_label = mixup_image(img, img2, label, label2, -lam_mag)\n",
    "            else:\n",
    "                mixed_img, mixed_label = mixup_image(img, img2, label, label2, 1+lam_mag)\n",
    "\n",
    "        if self.transform:\n",
    "            mixed_img = self.transform(mixed_img)\n",
    "\n",
    "        return mixed_img, mixed_label\n",
    "\n",
    "def mixup_input(dataset, lam_mag=0.5, lam_randomize=True):\n",
    "    chosen = set()\n",
    "    mixed_dataset = []\n",
    "    for idx, data in enumerate(dataset):\n",
    "        img = data[0]\n",
    "        idx2 = np.random.randint(0, len(dataset))\n",
    "        while (idx, idx2) in chosen:\n",
    "            idx2 = np.random.randint(0, len(dataset))\n",
    "\n",
    "        img2 = dataset[idx2][0]\n",
    "        if lam_randomize:\n",
    "            lam_mag *= np.random.rand()\n",
    "        mixed1 = mixup_image(img, img2, -lam_mag)\n",
    "        mixed2 = mixup_image(img, img2, 1+lam_mag)\n",
    "        plt.imshow(mixed2)\n",
    "        break\n",
    "\n",
    "# mixup_input(train_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "worth-harvest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fede27dbca0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZwklEQVR4nO2dbYxcZ3XH/2dmZ3dt7ybeXccvrN8Sx0UBAwndWqBUiJYWpQgpUJoIPqB8iDAfiFQkqipKpZJ+g6qA+FAhmSbCVCmQEihRlbZEUUtAqkI2juM4OBAnmMTY2Ilf2PXbzs7M6Ye5ljbhnv/M3nnb5vn/pNXO3jPPfc48c8/M7POfc465O4QQb35Kg3ZACNEfFOxCJIKCXYhEULALkQgKdiESQcEuRCIMdTLYzG4B8FUAZQD/5O5fYPefmJzy6S3bcm3dlgDZ2YrOFY1ip3PmCXUjNvL5CvhRzI1WxmUPaRQcx12MrNbl83VAkXMGQ06/ehzn587lPrjCwW5mZQD/COBPARwD8KSZPezuP4vGTG/Zhgf/40e5tkaDPtW51Mka1erx+dhczLYYzLfYiB2p1+sF/YjPyZZqsV7LPV4jl3DD4xMa8cOJI9ELKnuhrdbiD5p15gc5Z7T+7iTYyfoWuU4BwMn1aIvxNbJcP774158Mx3TyMX43gCPu/pK7VwF8G8CtHZxPCNFDOgn2aQCvLPn7WHZMCLEC6STY8z4H/c7nKTPbY2azZjZ75vRrHUwnhOiEToL9GIAtS/7eDOD4G+/k7nvdfcbdZyan1nUwnRCiEzoJ9icB7DSza81sGMDHATzcHbeEEN2m8G68u9fM7C4A/4Wm9Ha/uz/XYhQs2BWOjjOMyCcWm1AiRrJJG74ysrmojbzUlpgjZK2ix1YmjhjZYDYju/jExUjqYzv/5RJ7zDFUuQgtZA1L5XhUAQUiM4YmYxdJQClaK3KqjnR2d38EwCOdnEMI0R/0DTohEkHBLkQiKNiFSAQFuxCJoGAXIhE62o0vQikUQ5YvkpSIdsVexZiqxQTASO0oEXnKiY1mcrFxRKoJ1Ssma9F1JJJRfEY0wsSPeFSZnbCAPNU8Z5CQQ64QJq+xZWSyIsjzyeTNiCKZm3pnFyIRFOxCJIKCXYhEULALkQgKdiESoe+78axKWkS0Acr2Z9kucoPs/LOd9VJgojv/xEbrzBWsGRfuaDPFgCWF0FVefh03moREZgoXH6BJJvEGOSllRc43RJ5stsPPrrkiJbzi7CX2XAohkkDBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQt+lt6jeVpGKa0wmo/Iak/mII5EkQ0unEaOT2mlMQmG12pqNen6XRtApBgBKNKmiWAJKNIrJSbSmIBnH5Lxy8HZWr5FaeNEgcP8bBZNdojwkVlsvrEFH1lDv7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEjqQ3MzsKYB5AHUDN3Wfo/dFK5sknzpNjcgyRSKgPsSQTtajir5hEQqPSIctSIz6GmXnF6uRx4a1IRhzLemN+EBuV8/KhmYr0fEWzB5e//kyui30kGXuhpX3+yN3Vi1mIFY4+xguRCJ0GuwP4oZk9ZWZ7uuGQEKI3dPox/mZ3P25m6wE8ambPu/vjS++QvQjsAYC3TG/ucDohRFE6emd39+PZ71MAvg9gd8599rr7jLvPTE6t62Q6IUQHFA52M1tjZuNXbgP4IIBD3XJMCNFdOvkYvwHA97MstiEA/+Lu/8mHeCxf0YKI+TRYhk+JZS7ViS00hRIP694Tt7tqUVSStRmKTUDQuogsBynKGGcpNm3Ej8hYsOCkUz8KZMTlJwc25yLrQduDEWODva0G85GuXOG7NHtOCge7u78E4F1Fxwsh+oukNyESQcEuRCIo2IVIBAW7EImgYBciEVZMrzcq8URnKliEkMk4tL9WPKrAmFayFsvyIp4EuhGTIhtErmE+MnkwLCxKzsczw+K5ePZjYKDXB5mL1uYs1hcvkuWMPTHh06mCk0Ikj4JdiERQsAuRCAp2IRJBwS5EIgxgNz5/t7DQLjjNI+luzTJm4/kgdMu6kK1Bd/GjDA+yS8u29+kiL7+NFlMZ6DY4fczLb1FF67v1YD3o9R2tVeHWYfnonV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJ0GfpzeCBzlAPaqetJMoF6qoxpcaJtLLICqGV4qetFLx+s5ZXZeJkzRdjPwiGqM4fqckXyoZAw8n7UpnUGwyuqwZ5XA0jNQoLttFqhOsRy6XGitBF10eR3BkhxJsLBbsQiaBgFyIRFOxCJIKCXYhEULALkQgtpTczux/AhwGccvdd2bFJAN8BsB3AUQC3u/vZThxheUvFKrx1n0gpY1lXDSIpNoi8xrL2eEupoAYdzSosKCeRxxZl0tGMsoI+sqsnLkHX3Sy65kDynLEMtuhxF8zODH1o4z7fAHDLG47dDeAxd98J4LHsbyHECqZlsGf91s+84fCtAPZlt/cB+Eh33RJCdJui/7NvcPcTAJD9Xt89l4QQvaDnG3RmtsfMZs1s9szp13o9nRAioGiwnzSzTQCQ/T4V3dHd97r7jLvPTE6tKzidEKJTigb7wwDuyG7fAeAH3XFHCNEr2pHevgXg/QDWmdkxAJ8H8AUAD5rZnQBeBnBbe9M5LJKNaLuj7opvoQ8tbF7gtbGwjMNaW7GMuMDWYI+LLC97xCwDLNKGyiwrizwuJh2yNY6kSCblsWeswWRKdk4qz+bbmLRZDrxkvrcMdnf/RGD6QKuxQoiVg75BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkQv97vQUSilE5qT8+tLQFMg51vVhrsEKZbc35gqw3IuPwR0ysjVpoKpeCwpfE9zKbislypDBjlGXHer2xx1wnfnApMhbF6sE4b8RFKsvloEhl7IHe2YVIBQW7EImgYBciERTsQiSCgl2IRFCwC5EIfZfeIkmJJYdFsktYqK8FTOZjkhc830kPjmdG4gnJkiKyyxBZrKGgXVok7wC8p9gQKZRYJUvV8Hz/2dqXmYTG2p6xwp3B+nvgHwCUCmavMVmO18uMKpmSMeFcrFCpECIJFOxCJIKCXYhEULALkQgKdiESoa+78QYP2xqx9jho5I+hu5+Mom2Xgl1TlgBRpE4bEG78AwAunP9taDsdlOteXFwkfsSTjawej8cRxtaM5R6v18ku+NBoaGOqQK0WJ+REig17l6PJPwV3u2kiTzDSyvEZWX26eB4hRBIo2IVIBAW7EImgYBciERTsQiSCgl2IRGin/dP9AD4M4JS778qO3QvgUwBeze52j7s/0s6EkbTFWjyFYwoWp+Pjll+DjrYLIgktbKqSxdLKiz9/LrQ9+eSTuccXFhbCMdVqLMstepBZA+BdN90U2t6xa1fucSa9rZkYCW31QH4FQIv5RZIXS2hZJDJZnch8Ud09gF/fUVIOS1AKOkZ1XIPuGwBuyTn+FXe/MftpK9CFEIOjZbC7++MAzvTBFyFED+nkf/a7zOygmd1vZhNd80gI0ROKBvvXAOwAcCOAEwC+FN3RzPaY2ayZzZ45fbrgdEKITikU7O5+0t3r3iwR8nUAu8l997r7jLvPTE5NFfVTCNEhhYLdzDYt+fOjAA51xx0hRK9oR3r7FoD3A1hnZscAfB7A+83sRjTFo6MAPt3WbA6UIlmDSCGRbBGeq6UfrH0SkXECKYS1cSoqD3o9lng2rJsMbds2vyX3eInIQqfPxPuv1UYsvQ2RB/78z/Jf/6+/fic5X2gCrdfHpLfAxiRA1oaqRDLR2FNdZz4GOhpLBI3l6JiWwe7un8g5fF+rcUKIlYW+QSdEIijYhUgEBbsQiaBgFyIRFOxCJELf2z9FUNWloHzVL1jrqhLJXCImVC/HmWgjw/HT9tadO3KPj4/HhSOfemp/aBsei78JfeHSpdAWSZiTE1eHY2gxRyZDEVkxag3lLIuOQK9Teh3wKzyPBpEHo4KTrNuY3tmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCH2X3iIBghXyCzPRiORCCxQyKS8o/gcAhnwby5SLpB8AaBAfT506Edqefebp0Hb58uXc46+8/HI4pjwUXwbXXh/bjv/6eGh773tvzj3Osu/qpB9duRRn3znpe9YIrqsKyV6rk8uD9lhjlxW7rgJXWJFKNKJ4KdaLTgjxJkLBLkQiKNiFSAQFuxCJoGAXIhH6vBvvqAe7mXSXM0giaJDMA2dJCewljuye1+r5u8VsLpb/UCd15qauIaX4K/HTVkZ+C6VxUtl3aiquaVetV0Pb8RPxbvz6DRtzj5vFu+q0Xh9TV8iudfRUN9hON3nSGkELsOYwcj2ScR48bjqmFNVy1G68EMmjYBciERTsQiSCgl2IRFCwC5EICnYhEqGd9k9bAHwTwEYADQB73f2rZjYJ4DsAtqPZAup2dz/LzuUet93hskU+9UacXMDa+wwFCS0Al39KQTIGU4VY4sfVV10V2n7+wguhbf2mzaHtwoULucfH18bS2/nz50Pbb47H8tqRo78Kbd/+7kO5x2/7i4+HY0aGR0Mbk2aZaltdDGq1kaJ2zMYSrGiZOXIdRLXmamyuFlUbc11o4z41AJ9z9xsAvAfAZ8zsbQDuBvCYu+8E8Fj2txBihdIy2N39hLvvz27PAzgMYBrArQD2ZXfbB+AjPfJRCNEFlvU/u5ltB3ATgCcAbHD3E0DzBQHA+q57J4ToGm0Hu5mNAXgIwGfdfW4Z4/aY2ayZzZ4hrYGFEL2lrWA3swqagf6Au38vO3zSzDZl9k0ATuWNdfe97j7j7jOTk/F3sIUQvaVlsFtzm/w+AIfd/ctLTA8DuCO7fQeAH3TfPSFEt2gn6+1mAJ8E8KyZHciO3QPgCwAeNLM7AbwM4LZWJ3J3XF6MM73YuDxKJPsLJGOoHtbvAmrV/BpuAFAuDwczxa+ZvyLy1KlTr4a28xcvhrYqy8oKdKgakSJLI6tC28bpLaFt8/b8VlMAsGosX1YcXr0mHFNn5d1ItlzN4+dzIbh2RsqVeC5WL45JxLQWYWgK5dkSkd5YbcOIlsHu7j9BXCfyA8ueUQgxEPQNOiESQcEuRCIo2IVIBAW7EImgYBciEfpacPLipUvY/8zBXBsrvhhlsFWGY/dHKqSwYSNuM7RmVX7BRgAolfKlNy/FY/bvPxDaDhx4JrSdm58PbRu2bQ9tmzfnZ8QdOXIkHDNFilFu3bo1tO3Y+dbQtj2Q5U6+ejocsxBkqAFc8lqoLoS2UtBbaYi0fyoZk7VIthnR1xZJe7Mor5PJdRF1ol/qnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJ0FfprVav4cxvz+XaVq2KM6+GhvLdHCJZbxb1wgKwnchJa68aD22jq8Zyj7/4y2Px+dZeHdp27Lg2tJ2di4tAXrU+v48aADzxxE9zj79yLPaxthhLkR/72J+HtomJuD7B84efzz1+8jex9FZlaW+kYONFkiFYqQTZbaRKZZn0S2PSlrFClUR6s0AeZHJ0JMtduBCvhd7ZhUgEBbsQiaBgFyIRFOxCJIKCXYhE6OtuvDsQ5Toskl3EiYmJ3OMjo/mJKQCwYV3+GACokF38ublzoW3+fH5rJVhcs+z33hrXaZuejnfVz83Hu/FnL1ZD2+4/+P3c4+98x9vjuc6dC22jZI3Xro3bV126cCn3+IXzpAr5UFwXrk5qrpGNetTr+WvlpL4bUwWK1JIDgFqB3Xg2Jqp3x+rg6Z1diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQidBSejOzLQC+CWAjmj2V9rr7V83sXgCfAnClh9E97v4IP1kJpUBeOX06TpCYD2ScFy+dDceMlGMJYt1ELBmxJAgEEsno6jh5hiXr1GuxZMdkF/YKvXXzptzj5XJcky9KNALi+n8AUF2IE2jesvGa3OOvvHI8HDOyJk6GYvra3Fws51WrgfTm8fmqpBZeeSheR5bsskjankXSGym7Bw9q4bGyde3o7DUAn3P3/WY2DuApM3s0s33F3f+hjXMIIQZMO73eTgA4kd2eN7PDAKZ77ZgQorss6392M9sO4CYAT2SH7jKzg2Z2v5nFX1kTQgyctoPdzMYAPATgs+4+B+BrAHYAuBHNd/4vBeP2mNmsmc3Sr0oKIXpKW8FuZhU0A/0Bd/8eALj7SXeve7NR9NcB7M4b6+573X3G3WfWBD27hRC9p2WwW7MVx30ADrv7l5ccX7rt+1EAh7rvnhCiW7SzG38zgE8CeNbMDmTH7gHwCTO7Ec3d/qMAPt3OhB7IDJPr8qUaAFgMaqTVF34bz+OxLLRq1WhoK4FkVwUtg+qI57pwMciUA7BYjcctVEk7rEacHVYNtBcmvbFMqSEiNZXLsR/DQausHdu2hGMi3wGgRmrG1auXQ5vX89eYKGEwslaRTAYAdeJjJJUBQC2QYJkk2iBZgBHt7Mb/BPkNrrimLoRYUegbdEIkgoJdiERQsAuRCAp2IRJBwS5EIvS14GSj0QilKCYzWJD+wwoeWi2WY8qlWFqpLiyEttGhkdzjFSpP5Y8BeKFEKvHU4vkagfzDMqjyxZYrcxF5kKzV+fn89R8ict3oVfHzWSWtkNZPrQ1tjcX8jMl5cr4K8dFoXlmcIWileNziQv5a1T1+nqMsOifyn97ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQh9lt7quBxIb1MTk+G4SICIpDAA2Lx1c2gbGY6llcOHfxbafn38ZO7xVWNrwjFTU1OhrVKOCyzaMCn0CJKyFbx+N0j/siibDwCGiATopfictirfthAUgAQAX4z725VIb7byUCwdrl2zOvf45YuvhWMa1fnQxmTWqbH4+dy4YX1o80DOO/mb2Md6PX+u4aH4+dI7uxCJoGAXIhEU7EIkgoJdiERQsAuRCAp2IRKhr9JbpVLBhmvyJYhLF+LCjKUgI27XrreHY7Zu3hja5udiaWX16rHQdvFyfgbVkV++FI554RcvhjaW6TcxEffcWLMm9jEqHrk6kKAAoBL03wMAixVA2qtu1Wi+NHT5cpyNeGkxtjVIRtnc2bjn3/r1+b3vxohcOjYer9WWTRtC2/SmWF4brpBMRc9/bK+9FhdUnZ/Lvxb/7V8fCMfonV2IRFCwC5EICnYhEkHBLkQiKNiFSISWu/FmNgrgcQAj2f2/6+6fN7NJAN8BsB3N9k+3u3u8LQrAG45qkAjBEiQWLuXvPB448HQ45rlnYz9KpPjbUCVekm3bt+cev+GGG8Ix58/HyR2HDsXt8V56Kd7hP3v2XGgbGQnq5FXiHXdmW1WJk42GK/ktngBgeDjfxuaq09Zb8fNSLsd+bA1afW3duC0cs2VbnER19Zo42WWU7LgbeWwL1fxafiMj4+GYubGLuccr5Dlp5519AcAfu/u70GzPfIuZvQfA3QAec/edAB7L/hZCrFBaBrs3ufL2VMl+HMCtAPZlx/cB+EgvHBRCdId2+7OXsw6upwA86u5PANjg7icAIPsdf6NACDFw2gp2d6+7+40ANgPYbWa72p3AzPaY2ayZzZ4/H39zTQjRW5a1G+/u5wD8D4BbAJw0s00AkP0+FYzZ6+4z7j4zNhZvOAghekvLYDeza8xsbXZ7FYA/AfA8gIcB3JHd7Q4AP+iRj0KILtBOIswmAPvMrIzmi8OD7v7vZva/AB40szsBvAzgtlYncjgani9BXDUev+svXMyX3o6feCUcc3H+XGhjclglkIwA4Ec//nHu8eFA7gK41BTJUwAwPT0d2qrVX4S2cjlf/hkbi5NnhoIxANAI2gwBcQIHAMwF68/aWrEWT5cux9LsdddeH9rOBkkyUVITAFSG4/UYvy6W7EqlOJzqtVh6O3P6XO7x0dE4IWdqKj9RaojUyGsZ7O5+EMBNOcdPA/hAq/FCiJWBvkEnRCIo2IVIBAW7EImgYBciERTsQiSCRTXLejKZ2asAfpX9uQ5A3N+mf8iP1yM/Xs//Nz+2ufs1eYa+BvvrJjabdfeZgUwuP+RHgn7oY7wQiaBgFyIRBhnsewc491Lkx+uRH6/nTePHwP5nF0L0F32MFyIRBhLsZnaLmf3czI6Y2cBq15nZUTN71swOmNlsH+e938xOmdmhJccmzexRM3sh+x33f+qtH/ea2a+zNTlgZh/qgx9bzOy/zeywmT1nZn+ZHe/rmhA/+romZjZqZj81s2cyP/4uO97Zerh7X38AlAG8COA6AMMAngHwtn77kflyFMC6Acz7PgDvBnBoybG/B3B3dvtuAF8ckB/3AvirPq/HJgDvzm6PA/gFgLf1e02IH31dEwAGYCy7XQHwBID3dLoeg3hn3w3giLu/5O5VAN9Gs3hlMrj74wDOvOFw3wt4Bn70HXc/4e77s9vzAA4DmEaf14T40Ve8SdeLvA4i2KcBLK06cQwDWNAMB/BDM3vKzPYMyIcrrKQCnneZ2cHsY37P/51YipltR7N+wkCLmr7BD6DPa9KLIq+DCHbLOTYoSeBmd383gD8D8Bkze9+A/FhJfA3ADjR7BJwA8KV+TWxmYwAeAvBZd5/r17xt+NH3NfEOirxGDCLYjwHYsuTvzQCOD8APuPvx7PcpAN9H81+MQdFWAc9e4+4nswutAeDr6NOamFkFzQB7wN2/lx3u+5rk+TGoNcnmPodlFnmNGESwPwlgp5lda2bDAD6OZvHKvmJma8xs/MptAB8EEPdj6j0rooDnlYsp46Pow5qYmQG4D8Bhd//yElNf1yTyo99r0rMir/3aYXzDbuOH0NzpfBHA3wzIh+vQVAKeAfBcP/0A8C00Pw4uovlJ504AU2i20Xoh+z05ID/+GcCzAA5mF9emPvjxh2j+K3cQwIHs50P9XhPiR1/XBMA7ATydzXcIwN9mxztaD32DTohE0DfohEgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCL8HwKKidWahhr3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data_raw[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "material-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mixup = MixupInputDataset(train_data_raw, lam_mag=0.9, lam_random=False, lam_direction='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "metric-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee11f3c340>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = cifar_mixup[100][0]\n",
    "# print(out.min(), out.max(), out.mean(), out.std())\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numeric-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ood_data = TinyImages(transform=trn.Compose(\n",
    "#     [trn.ToTensor(), trn.ToPILImage(), trn.RandomCrop(32, padding=4),\n",
    "#      trn.RandomHorizontalFlip(), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "\n",
    "ood_data = MixupInputDataset(train_data_raw, lam_mag=0.5, lam_random=False, transform=train_transform)\n",
    "\n",
    "pin = False\n",
    "\n",
    "train_loader_in = torch.utils.data.DataLoader(\n",
    "    train_data_in,\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.prefetch, pin_memory=False)\n",
    "\n",
    "train_loader_out = torch.utils.data.DataLoader(\n",
    "    ood_data,\n",
    "    batch_size=args.oe_batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.prefetch, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "critical-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Create model\n",
    "if args.model == 'resnet18':\n",
    "    net = ResNet18(num_classes=10)\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "# Restore model\n",
    "model_found = False\n",
    "if args.load != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = os.path.join(args.load, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                  '_baseline_epoch_' + str(i) + '.pt')\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            model_found = True\n",
    "            break\n",
    "    if not model_found:\n",
    "        assert False, \"could not find model to restore\"\n",
    "\n",
    "if args.ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "\n",
    "if args.ngpu > 0:\n",
    "    net.cuda()\n",
    "    torch.cuda.manual_seed(1)\n",
    "\n",
    "# cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args.epochs * len(train_loader_in),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dietary-medium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advised-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11173962"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "private-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /////////////// Training ///////////////\n",
    "\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "\n",
    "    # start at a random point of the outlier dataset; this induces more randomness without obliterating locality\n",
    "#     train_loader_out.dataset.offset = np.random.randint(len(train_loader_out.dataset))\n",
    "    for in_set, out_set in tqdm(zip(train_loader_in, train_loader_out)):\n",
    "        data = torch.cat((in_set[0], out_set[0]), 0)\n",
    "        target = in_set[1]\n",
    "\n",
    "        if args.ngpu > 0:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = F.cross_entropy(x[:len(in_set[0])], target)\n",
    "        # cross-entropy from softmax distribution to uniform distribution\n",
    "        loss += 0.5 * -(x[len(in_set[0]):].mean(1) - torch.logsumexp(x[len(in_set[0]):], dim=1)).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if args.ngpu > 0:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)\n",
    "\n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# if args.test:\n",
    "#     test()\n",
    "#     print(state)\n",
    "#     exit()\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args.save):\n",
    "    os.makedirs(args.save)\n",
    "if not os.path.isdir(args.save):\n",
    "    raise Exception('%s is not a dir' % args.save)\n",
    "\n",
    "with open(os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                  '_oe_tune_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "neural-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enormous-cabinet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a097550406e74ba38902f85778e77da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f37d10cb5dd437fbea061dd23029ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-58d80ff9c9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbegin_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-23b0ae5820e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Beginning Training\\n')\n",
    "\n",
    "# Main loop\n",
    "for epoch in tqdm(range(0, args.epochs)):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                            '_oe_tune_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                             '_oe_tune_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                      '_oe_tune_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy'],\n",
    "        ))\n",
    "\n",
    "    # # print state with rounded decimals\n",
    "    # print({k: round(v, 4) if isinstance(v, float) else v for k, v in state.items()})\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "conditional-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.save = 'ckpts'\n",
    "best_path = os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                            '_oe_scratch_best.pt')\n",
    "checkpoint = torch.load(best_path, map_location=torch.device('cpu'))\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coral-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ood_test_data = dset.CIFAR100('./data', download=True, transform=test_transform, train=False)\n",
    "ood_test_loader = torch.utils.data.DataLoader(\n",
    "    ood_test_data,\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.prefetch, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "incoming-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd0a50141df4ddabbcbed5979f268c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2240495709f9484eb90a8f79cef2ace1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test function\n",
    "def get_probs(loader):\n",
    "    net.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader):\n",
    "            if args.ngpu > 0:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = net(data)\n",
    "            score = F.softmax(output[0], dim=0)\n",
    "            scores.append(score.detach().cpu().numpy())\n",
    "            break\n",
    "    return np.array(scores)\n",
    "\n",
    "ood_probs = get_probs(ood_test_loader)\n",
    "ood_msp = ood_probs.max(axis=1)\n",
    "\n",
    "id_probs = get_probs(test_loader)\n",
    "id_msp = id_probs.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "municipal-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7551151], dtype=float32), array([0.5046329], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_msp, id_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-intro",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-violin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-bacteria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-answer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "graduate-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "controlling-emergency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "inappropriate-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def compute_auroc(id_pps, ood_pps, normalize=False, return_curve=False):\n",
    "    y = np.concatenate((np.ones_like(ood_pps), np.zeros_like(id_pps)))\n",
    "    scores = np.concatenate((ood_pps, id_pps))\n",
    "    if normalize:\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    if return_curve:\n",
    "        return roc_curve(y, scores)\n",
    "    else:\n",
    "        return 100*roc_auc_score(y, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "scientific-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_msp = np.load('id_msp.npy')\n",
    "ood_msp = np.load('ood_msp.npy')\n",
    "\n",
    "oe_id_msp = np.load('oe_id_msp.npy')\n",
    "oe_ood_msp = np.load('oe_ood_msp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "colored-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.684196"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-id_msp, -ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acceptable-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.482409"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-oe_id_msp, -oe_ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-excellence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ood] *",
   "language": "python",
   "name": "conda-env-ood-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
