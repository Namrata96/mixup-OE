{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occasional-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dataset': 'cifar10', 'decay': 0.0005, 'epochs': 10, 'learning_rate': 0.001, 'load': '', 'model': 'resnet18', 'momentum': 0.9, 'ngpu': 0, 'oe_batch_size': 256, 'prefetch': 4, 'save': './snapshots/oe_scratch', 'test_bs': 200}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Tunes a CIFAR Classifier with OE',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--dataset', type=str, choices=['cifar10', 'cifar100'], default='cifar10',\n",
    "                    help='Choose between CIFAR-10, CIFAR-100.')\n",
    "parser.add_argument('--model', '-m', type=str, default='resnet18',\n",
    "                    choices=['resnet18', 'resnet50'], help='Choose architecture.')\n",
    "# parser.add_argument('--calibration', '-c', action='store_true',\n",
    "#                     help='Train a model to be used for calibration. This holds out some data for validation.')\n",
    "# Optimization options\n",
    "parser.add_argument('--epochs', '-e', type=int, default=10, help='Number of epochs to train.')\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=0.001, help='The initial learning rate.')\n",
    "parser.add_argument('--batch_size', '-b', type=int, default=128, help='Batch size.')\n",
    "parser.add_argument('--oe_batch_size', type=int, default=256, help='Batch size.')\n",
    "parser.add_argument('--test_bs', type=int, default=200)\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='Momentum.')\n",
    "parser.add_argument('--decay', '-d', type=float, default=0.0005, help='Weight decay (L2 penalty).')\n",
    "# Checkpoints\n",
    "parser.add_argument('--save', '-s', type=str, default='./snapshots/oe_scratch', help='Folder to save checkpoints.')\n",
    "parser.add_argument('--load', '-l', type=str, default='', help='Checkpoint path to resume / test.')\n",
    "# parser.add_argument('--test', '-t', action='store_true', help='Test only flag.')\n",
    "# Acceleration\n",
    "parser.add_argument('--ngpu', type=int, default=0, help='0 = CPU.')\n",
    "parser.add_argument('--prefetch', type=int, default=4, help='Pre-fetching threads.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "state = {k: v for k, v in args._get_kwargs()}\n",
    "print(state)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetOld(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetOld, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def forward_penul(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_penul(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
    "\n",
    "def ResNet34(num_classes=10):\n",
    "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet50(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet101(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
    "\n",
    "def ResNet152(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,8,36,3], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ahead-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = trn.Compose([trn.RandomHorizontalFlip(), trn.RandomCrop(32, padding=4),\n",
    "                               trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    train_data_in = dset.CIFAR10('./data', train=True, transform=train_transform)\n",
    "    train_data_raw = dset.CIFAR10('./data', train=True)\n",
    "    test_data = dset.CIFAR10('./data', train=False, transform=test_transform)\n",
    "    num_classes = 10\n",
    "else:\n",
    "    train_data_in = dset.CIFAR100('./data', train=True, transform=train_transform)\n",
    "    test_data = dset.CIFAR100('./data', train=False, transform=test_transform)\n",
    "    num_classes = 100\n",
    "\n",
    "calib_indicator = ''\n",
    "# if args.calibration:\n",
    "#     train_data_in, val_data = validation_split(train_data_in, val_share=0.1)\n",
    "#     calib_indicator = '_calib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "general-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff0b91887c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data_raw[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facial-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def mixup_image(img1, img2, label1, label2, lam):\n",
    "    mixed_img = lam*np.asarray(img1) + (1-lam)*np.asarray(img2)\n",
    "    mixed_label = lam*label1 + (1-lam)*label2\n",
    "    return Image.fromarray(mixed_img.clip(0, 255).astype('uint8'), 'RGB'), mixed_label\n",
    "\n",
    "class MixupInputDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, lam_mag=0.5, lam_random=False, lam_direction='random'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.lam_mag = lam_mag\n",
    "        self.lam_random = lam_random\n",
    "        self.lam_direction = lam_direction\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img, label = self.dataset[idx]\n",
    "        idx2 = np.random.randint(0, len(self.dataset))\n",
    "        img2, label2 = self.dataset[idx2]\n",
    "        \n",
    "        if self.lam_random:\n",
    "            lam_mag = self.lam_mag * (0.5 + np.random.rand()/2)\n",
    "        else:\n",
    "            lam_mag = self.lam_mag\n",
    "        \n",
    "        print(lam_mag)\n",
    "        \n",
    "        if self.lam_direction == 'neg':\n",
    "            mixed_img, mixed_label = mixup_image(img, img2, label, label2, -lam_mag)\n",
    "        elif self.lam_direction == 'pos':\n",
    "            mixed_img, mixed_label = mixup_image(img, img2, label, label2, 1+lam_mag)\n",
    "        else:\n",
    "            if np.random.rand() > 0.5:\n",
    "                mixed_img, mixed_label = mixup_image(img, img2, label, label2, -lam_mag)\n",
    "            else:\n",
    "                mixed_img, mixed_label = mixup_image(img, img2, label, label2, 1+lam_mag)\n",
    "\n",
    "        if self.transform:\n",
    "            mixed_img = self.transform(mixed_img)\n",
    "\n",
    "        return mixed_img, mixed_label\n",
    "\n",
    "def mixup_input(dataset, lam_mag=0.5, lam_randomize=True):\n",
    "    chosen = set()\n",
    "    mixed_dataset = []\n",
    "    for idx, data in enumerate(dataset):\n",
    "        img = data[0]\n",
    "        idx2 = np.random.randint(0, len(dataset))\n",
    "        while (idx, idx2) in chosen:\n",
    "            idx2 = np.random.randint(0, len(dataset))\n",
    "\n",
    "        img2 = dataset[idx2][0]\n",
    "        if lam_randomize:\n",
    "            lam_mag *= np.random.rand()\n",
    "        mixed1 = mixup_image(img, img2, -lam_mag)\n",
    "        mixed2 = mixup_image(img, img2, 1+lam_mag)\n",
    "        plt.imshow(mixed2)\n",
    "        break\n",
    "\n",
    "# mixup_input(train_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wrong-generation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff0f88ad5b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data_raw[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comprehensive-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mixup = MixupInputDataset(train_data_raw, lam_mag=0.9, lam_random=False, lam_direction='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "visible-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff0c0285c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = cifar_mixup[100][0]\n",
    "# print(out.min(), out.max(), out.mean(), out.std())\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "spiritual-gallery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff0c06eb640>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "plt.imshow(random_noise(np.asarray(train_data_raw[100][0]), mean=0, var=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "central-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.5908195557912389, 0.42346489120078457)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = random_noise(np.asarray(train_data_raw[100][0]), mean=0, var=0.1)\n",
    "\n",
    "test.min(), test.max(), test.mean(), test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cutting-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "class NoiseInputDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, mean=0, var=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img, label = self.dataset[idx]\n",
    "        noise_img = random_noise(np.asarray(img), mean=self.mean, var=self.var)\n",
    "        noise_img = Image.fromarray(noise_img, 'RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            noise_img = self.transform(noise_img)\n",
    "\n",
    "        return noise_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "successful-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ood_data = TinyImages(transform=trn.Compose(\n",
    "#     [trn.ToTensor(), trn.ToPILImage(), trn.RandomCrop(32, padding=4),\n",
    "#      trn.RandomHorizontalFlip(), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "\n",
    "# ood_data = MixupInputDataset(train_data_raw, lam_mag=0.5, lam_random=False, transform=train_transform)\n",
    "ood_data = NoiseInputDataset(train_data_raw, mean=0, var=0.01, transform=train_transform)\n",
    "\n",
    "pin = False\n",
    "\n",
    "train_loader_in = torch.utils.data.DataLoader(\n",
    "    train_data_in,\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.prefetch, pin_memory=False)\n",
    "\n",
    "train_loader_out = torch.utils.data.DataLoader(\n",
    "    ood_data,\n",
    "    batch_size=args.oe_batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.prefetch, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "sunset-adaptation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([256, 3, 32, 32])\n",
      "tensor(-1.9889) tensor(2.1256) tensor(-0.1609) tensor(1.2975)\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_loader_out:\n",
    "    print(type(img), img.size())\n",
    "    print(img[0].min(), img[0].max(), img[0].mean(), img[0].std())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "vital-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([128, 3, 32, 32])\n",
      "tensor(-1.9889) tensor(2.0405) tensor(0.2483) tensor(1.2900)\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_loader_in:\n",
    "    print(type(img), img.size())\n",
    "    print(img[0].min(), img[0].max(), img[0].mean(), img[0].std())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "random-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Create model\n",
    "if args.model == 'resnet18':\n",
    "    net = ResNet18(num_classes=10)\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "# Restore model\n",
    "model_found = False\n",
    "if args.load != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = os.path.join(args.load, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                  '_baseline_epoch_' + str(i) + '.pt')\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            model_found = True\n",
    "            break\n",
    "    if not model_found:\n",
    "        assert False, \"could not find model to restore\"\n",
    "\n",
    "if args.ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "\n",
    "if args.ngpu > 0:\n",
    "    net.cuda()\n",
    "    torch.cuda.manual_seed(1)\n",
    "\n",
    "# cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args.epochs * len(train_loader_in),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "julian-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unexpected-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11173962"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "approximate-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /////////////// Training ///////////////\n",
    "\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "\n",
    "    # start at a random point of the outlier dataset; this induces more randomness without obliterating locality\n",
    "#     train_loader_out.dataset.offset = np.random.randint(len(train_loader_out.dataset))\n",
    "    for in_set, out_set in tqdm(zip(train_loader_in, train_loader_out)):\n",
    "        data = torch.cat((in_set[0], out_set[0]), 0)\n",
    "        target = in_set[1]\n",
    "\n",
    "        if args.ngpu > 0:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = F.cross_entropy(x[:len(in_set[0])], target)\n",
    "        # cross-entropy from softmax distribution to uniform distribution\n",
    "        loss += 0.5 * -(x[len(in_set[0]):].mean(1) - torch.logsumexp(x[len(in_set[0]):], dim=1)).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if args.ngpu > 0:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)\n",
    "\n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# if args.test:\n",
    "#     test()\n",
    "#     print(state)\n",
    "#     exit()\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args.save):\n",
    "    os.makedirs(args.save)\n",
    "if not os.path.isdir(args.save):\n",
    "    raise Exception('%s is not a dir' % args.save)\n",
    "\n",
    "with open(os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                  '_oe_tune_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "restricted-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "global-tractor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a097550406e74ba38902f85778e77da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f37d10cb5dd437fbea061dd23029ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-58d80ff9c9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbegin_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-23b0ae5820e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ood/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Beginning Training\\n')\n",
    "\n",
    "# Main loop\n",
    "for epoch in tqdm(range(0, args.epochs)):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                            '_oe_tune_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                             '_oe_tune_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                                      '_oe_tune_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy'],\n",
    "        ))\n",
    "\n",
    "    # # print state with rounded decimals\n",
    "    # print({k: round(v, 4) if isinstance(v, float) else v for k, v in state.items()})\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excess-movement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.save = 'ckpts'\n",
    "best_path = os.path.join(args.save, args.dataset + calib_indicator + '_' + args.model +\n",
    "                            '_oe_scratch_best.pt')\n",
    "checkpoint = torch.load(best_path, map_location=torch.device('cpu'))\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "banner-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ood_test_data = dset.CIFAR100('./data', download=True, transform=test_transform, train=False)\n",
    "ood_test_loader = torch.utils.data.DataLoader(\n",
    "    ood_test_data,\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.prefetch, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "saved-mixer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd0a50141df4ddabbcbed5979f268c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2240495709f9484eb90a8f79cef2ace1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test function\n",
    "def get_probs(loader):\n",
    "    net.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader):\n",
    "            if args.ngpu > 0:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = net(data)\n",
    "            score = F.softmax(output[0], dim=0)\n",
    "            scores.append(score.detach().cpu().numpy())\n",
    "            break\n",
    "    return np.array(scores)\n",
    "\n",
    "ood_probs = get_probs(ood_test_loader)\n",
    "ood_msp = ood_probs.max(axis=1)\n",
    "\n",
    "id_probs = get_probs(test_loader)\n",
    "id_msp = id_probs.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "intense-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7551151], dtype=float32), array([0.5046329], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_msp, id_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-denver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-burke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-manner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-cooking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "blond-depth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "absolute-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "pediatric-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def compute_auroc(id_pps, ood_pps, normalize=False, return_curve=False):\n",
    "    y = np.concatenate((np.ones_like(ood_pps), np.zeros_like(id_pps)))\n",
    "    scores = np.concatenate((ood_pps, id_pps))\n",
    "    if normalize:\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    if return_curve:\n",
    "        return roc_curve(y, scores)\n",
    "    else:\n",
    "        return 100*roc_auc_score(y, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facial-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "id_msp = np.load('results/id_msp.npy')\n",
    "ood_msp = np.load('results/ood_msp.npy')\n",
    "\n",
    "oe_id_msp = np.load('results/oe_inter_id_msp.npy')\n",
    "oe_ood_msp = np.load('results/oe_inter_ood_msp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dangerous-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.684196"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-id_msp, -ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "center-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.703213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-oe_id_msp, -oe_ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "disciplinary-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "base_path = 'results/90'\n",
    "\n",
    "id_msp = np.load(f'{base_path}/id_msp.npy')\n",
    "ood_msp = np.load(f'{base_path}/ood_msp.npy')\n",
    "\n",
    "oe_inter_id_msp = np.load(f'{base_path}/oe_inter_id_msp.npy')\n",
    "oe_inter_ood_msp = np.load(f'{base_path}/oe_inter_ood_msp.npy')\n",
    "\n",
    "oe_noise_id_msp = np.load(f'{base_path}/oe_noise_id_msp.npy')\n",
    "oe_noise_ood_msp = np.load(f'{base_path}/oe_noise_ood_msp.npy')\n",
    "\n",
    "oe_extra_id_msp = np.load(f'{base_path}/oe_extra_id_msp.npy')\n",
    "oe_extra_ood_msp = np.load(f'{base_path}/oe_extra_ood_msp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "historical-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.82450100000001"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-id_msp, -ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "subject-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.87531349999999"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-oe_inter_id_msp, -oe_inter_ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "shaped-trinity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.327596"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-oe_noise_id_msp, -oe_noise_ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fatty-intro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.393634"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(-oe_extra_id_msp, -oe_extra_ood_msp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ood] *",
   "language": "python",
   "name": "conda-env-ood-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
